{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be0401e",
   "metadata": {},
   "source": [
    "# Phase 4: Temporal Windowing of Keypoint Sequences\n",
    "\n",
    "## Why Temporal Windows?\n",
    "\n",
    "**LSTM expects fixed-size inputs**, but videos have variable length.\n",
    "\n",
    "**Solution:** Create overlapping temporal windows from keypoint sequences\n",
    "- **Window size**: 25 frames (1 second @ 25 FPS) - captures mudra shape over time\n",
    "- **Step size**: 5 frames - creates overlap for more training samples\n",
    "- **This is CRITICAL** - poor windowing causes label misalignment and wrong predictions\n",
    "\n",
    "## What We'll Do\n",
    "\n",
    "1. Load extracted keypoints from training videos\n",
    "2. Create overlapping temporal windows (25 frames each)\n",
    "3. Create corresponding labels for each window\n",
    "4. Reshape for LSTM input (batch_size, time_steps, features)\n",
    "5. Verify window integrity and label alignment\n",
    "6. Split into train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c421ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/vidanadheera/Documents/SEM - 6/CV/Mudra_recognition_new/src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from windowing import create_temporal_windows, create_labeled_windows, reshape_for_lstm, verify_window_integrity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set base paths\n",
    "BASE_DIR = Path('/Users/vidanadheera/Documents/SEM - 6/CV/Mudra_recognition_new')\n",
    "KEYPOINTS_DIR = BASE_DIR / 'keypoints'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEMPORAL WINDOWING AND DATA PREPARATION\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "print(f\"Loading keypoints from: {KEYPOINTS_DIR}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cfb794",
   "metadata": {},
   "source": [
    "## Section 1: Load Keypoint Data\n",
    "\n",
    "Load pre-extracted keypoints from Phase 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keypoints\n",
    "pataka_keypoints = np.load(str(KEYPOINTS_DIR / 'pataka_keypoints.npy'))\n",
    "tripataka_keypoints = np.load(str(KEYPOINTS_DIR / 'tripataka_keypoints.npy'))\n",
    "\n",
    "print(\"Loaded keypoints:\")\n",
    "print(f\"  Pataka: {pataka_keypoints.shape}\")\n",
    "print(f\"  Tripataka: {tripataka_keypoints.shape}\")\n",
    "print()\n",
    "\n",
    "# Verify shapes\n",
    "assert pataka_keypoints.shape[1] == 21, \"Expected 21 landmarks\"\n",
    "assert pataka_keypoints.shape[2] == 3, \"Expected 3 coordinates (x,y,z)\"\n",
    "assert tripataka_keypoints.shape[1] == 21, \"Expected 21 landmarks\"\n",
    "assert tripataka_keypoints.shape[2] == 3, \"Expected 3 coordinates (x,y,z)\"\n",
    "\n",
    "print(\"✓ Keypoint shapes verified\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5ad2f",
   "metadata": {},
   "source": [
    "## Section 2: Create Temporal Windows with Labels\n",
    "\n",
    "This is the CRITICAL step for avoiding label misalignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window parameters\n",
    "WINDOW_SIZE = 25  # frames (1 second @ 25 fps)\n",
    "STEP_SIZE = 5     # frames\n",
    "\n",
    "print(\"Window Parameters:\")\n",
    "print(f\"  Window size: {WINDOW_SIZE} frames ({WINDOW_SIZE/25:.2f} seconds)\")\n",
    "print(f\"  Step size: {STEP_SIZE} frames\")\n",
    "print(f\"  Expected window count (Pataka): {(len(pataka_keypoints) - WINDOW_SIZE) // STEP_SIZE + 1}\")\n",
    "print(f\"  Expected window count (Tripataka): {(len(tripataka_keypoints) - WINDOW_SIZE) // STEP_SIZE + 1}\\n\")\n",
    "\n",
    "# Create labeled windows\n",
    "sequences_dict = {\n",
    "    'Pataka': [pataka_keypoints],\n",
    "    'Tripataka': [tripataka_keypoints]\n",
    "}\n",
    "\n",
    "windows, labels, label_to_idx, idx_to_label, window_metadata = create_labeled_windows(\n",
    "    sequences_dict,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    step_size=STEP_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Labeled windows created:\")\n",
    "print(f\"  Total windows: {len(windows)}\")\n",
    "print(f\"  Windows shape: {windows.shape}\")\n",
    "print(f\"  Labels shape: {labels.shape}\")\n",
    "print(f\"  Label mapping: {label_to_idx}\\n\")\n",
    "\n",
    "# Verify window integrity\n",
    "verify_window_integrity(windows, labels, window_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae65c75",
   "metadata": {},
   "source": [
    "## Section 3: Reshape for LSTM Input\n",
    "\n",
    "LSTM expects input shape: (batch_size, time_steps, features)\n",
    "\n",
    "We need to flatten landmarks and coordinates into a single feature dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM\n",
    "X = reshape_for_lstm(windows)\n",
    "\n",
    "print(f\"LSTM Input prepared:\")\n",
    "print(f\"  Input shape: {X.shape}\")\n",
    "print(f\"  Batch size (samples): {X.shape[0]}\")\n",
    "print(f\"  Time steps (frames per window): {X.shape[1]}\")\n",
    "print(f\"  Features (landmarks × coordinates): {X.shape[2]}\")\n",
    "print(f\"  Calculation: 21 landmarks × 3 coordinates = 63 features\\n\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(label_to_idx)\n",
    "y = to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "print(f\"Labels one-hot encoded:\")\n",
    "print(f\"  Shape: {y.shape}\")\n",
    "print(f\"  Classes: {num_classes}\")\n",
    "print(f\"  Class names: {idx_to_label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd80d6",
   "metadata": {},
   "source": [
    "## Section 4: Train-Validation Split\n",
    "\n",
    "Split data for model training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ece7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels  # Ensure balanced split\n",
    ")\n",
    "\n",
    "print(\"Train-Validation Split:\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Validation samples: {len(X_val)}\")\n",
    "print(f\"  Total: {len(X_train) + len(X_val)}\")\n",
    "print(f\"  Split ratio: {100 * len(X_train) / len(X):.0f}% train / {100 * len(X_val) / len(X):.0f}% val\\n\")\n",
    "\n",
    "# Class distribution\n",
    "train_dist = np.sum(y_train, axis=0)\n",
    "val_dist = np.sum(y_val, axis=0)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(f\"  Training:\")\n",
    "for i, name in idx_to_label.items():\n",
    "    print(f\"    {name}: {int(train_dist[i])} ({100*train_dist[i]/len(X_train):.1f}%)\")\n",
    "print(f\"  Validation:\")\n",
    "for i, name in idx_to_label.items():\n",
    "    print(f\"    {name}: {int(val_dist[i])} ({100*val_dist[i]/len(X_val):.1f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c240ee7",
   "metadata": {},
   "source": [
    "## Section 5: Save Prepared Data\n",
    "\n",
    "Save the prepared data for use in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64244305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for training\n",
    "data_dir = BASE_DIR / 'data' / 'prepared'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(str(data_dir / 'X_train.npy'), X_train)\n",
    "np.save(str(data_dir / 'X_val.npy'), X_val)\n",
    "np.save(str(data_dir / 'y_train.npy'), y_train)\n",
    "np.save(str(data_dir / 'y_val.npy'), y_val)\n",
    "\n",
    "# Also save metadata\n",
    "import json\n",
    "metadata = {\n",
    "    'label_to_idx': label_to_idx,\n",
    "    'idx_to_label': {str(k): v for k, v in idx_to_label.items()},\n",
    "    'window_size': WINDOW_SIZE,\n",
    "    'step_size': STEP_SIZE,\n",
    "    'num_features': X.shape[2],\n",
    "    'num_classes': num_classes\n",
    "}\n",
    "\n",
    "with open(str(data_dir / 'metadata.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Data saved to {data_dir}\")\n",
    "print(f\"  - X_train.npy: {X_train.shape}\")\n",
    "print(f\"  - X_val.npy: {X_val.shape}\")\n",
    "print(f\"  - y_train.npy: {y_train.shape}\")\n",
    "print(f\"  - y_val.npy: {y_val.shape}\")\n",
    "print(f\"  - metadata.json\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9a22d",
   "metadata": {},
   "source": [
    "## Summary: Phase 4 Complete ✓\n",
    "\n",
    "**What we've accomplished:**\n",
    "1. ✓ Loaded extracted keypoint sequences\n",
    "2. ✓ Created overlapping temporal windows (25 frames, step 5)\n",
    "3. ✓ Created label-window alignment (CRITICAL for correctness)\n",
    "4. ✓ Reshaped for LSTM input: (batch, time_steps=25, features=63)\n",
    "5. ✓ Split into balanced train/validation sets\n",
    "6. ✓ Saved prepared data\n",
    "\n",
    "**Key insight:**\n",
    "- Proper windowing and label alignment is CRITICAL\n",
    "- Poor alignment causes the model to learn incorrect mudra-label mappings\n",
    "- This was likely the cause of wrong predictions in the previous attempt\n",
    "\n",
    "**Data ready for training:**\n",
    "- X_train/X_val: (num_samples, 25, 63) - temporal windows of hand keypoints\n",
    "- y_train/y_val: (num_samples, 2) - one-hot encoded labels\n",
    "\n",
    "**Next steps (Phase 5):**\n",
    "- Build and train Bi-Directional LSTM\n",
    "- Monitor training/validation loss and accuracy\n",
    "- Save the trained model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
