{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae1c10c5",
   "metadata": {},
   "source": [
    "# Phase 5: Bi-Directional LSTM Model Training\n",
    "\n",
    "## Why LSTM for Mudra Recognition?\n",
    "\n",
    "**Problem:** Mudras are TEMPORAL sequences - hand shape changes over time\n",
    "\n",
    "**Why not CNN alone?** CNN only looks at single frames (spatial), ignores temporal context\n",
    "\n",
    "**Why LSTM?**\n",
    "1. **Temporal Modeling**: Processes sequence of frames, understands hand movement\n",
    "2. **Long-range Dependencies**: Captures mudra transitions and sustained poses\n",
    "3. **Bidirectional**: Processes frames forward AND backward for better context\n",
    "4. **Suitable for Review**: Simple, interpretable, well-established for sequence classification\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "- **Input:** (batch, 25 frames, 63 keypoint features)\n",
    "- **Bi-LSTM:** 64 units, forward + backward processing\n",
    "- **Dense layers:** 32 → output\n",
    "- **Output:** Softmax over 2 classes (Pataka, Tripataka)\n",
    "- **Loss:** Categorical cross-entropy\n",
    "- **Optimizer:** Adam\n",
    "\n",
    "## What We'll Do\n",
    "\n",
    "1. Build the Bi-LSTM model\n",
    "2. Load prepared training data\n",
    "3. Train with early stopping\n",
    "4. Plot training curves\n",
    "5. Evaluate on validation set\n",
    "6. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/vidanadheera/Documents/SEM - 6/CV/Mudra_recognition_new/src')\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from model import build_lstm_model, train_model, evaluate_model, plot_training_history, save_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set base paths\n",
    "BASE_DIR = Path('/Users/vidanadheera/Documents/SEM - 6/CV/Mudra_recognition_new')\n",
    "DATA_DIR = BASE_DIR / 'data' / 'prepared'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LSTM MODEL TRAINING\")\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbcdbe",
   "metadata": {},
   "source": [
    "## Section 1: Load Prepared Training Data\n",
    "\n",
    "Load the windowed temporal sequences and labels from Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ec8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = np.load(str(DATA_DIR / 'X_train.npy'))\n",
    "X_val = np.load(str(DATA_DIR / 'X_val.npy'))\n",
    "y_train = np.load(str(DATA_DIR / 'y_train.npy'))\n",
    "y_val = np.load(str(DATA_DIR / 'y_val.npy'))\n",
    "\n",
    "# Load metadata\n",
    "with open(str(DATA_DIR / 'metadata.json'), 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "label_to_idx = metadata['label_to_idx']\n",
    "idx_to_label = {int(k): v for k, v in metadata['idx_to_label'].items()}\n",
    "num_classes = metadata['num_classes']\n",
    "window_size = metadata['window_size']\n",
    "num_features = metadata['num_features']\n",
    "\n",
    "print(\"Training data loaded:\")\n",
    "print(f\"  X_train: {X_train.shape} - (samples, time_steps, features)\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  y_train: {y_train.shape} - (samples, classes)\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "print(f\"\\nMetadata:\")\n",
    "print(f\"  Classes: {list(label_to_idx.keys())}\")\n",
    "print(f\"  Window size: {window_size} frames\")\n",
    "print(f\"  Features per frame: {num_features}\")\n",
    "print(f\"  Model input shape: ({window_size}, {num_features})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f5688",
   "metadata": {},
   "source": [
    "## Section 2: Build Bi-Directional LSTM Model\n",
    "\n",
    "Build the neural network architecture for temporal mudra classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_shape = (window_size, num_features)\n",
    "model = build_lstm_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    lstm_units=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725f5d5",
   "metadata": {},
   "source": [
    "## Section 3: Train the Model\n",
    "\n",
    "Train the LSTM on temporal windows with early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"\\nStarting training...\\n\")\n",
    "history = train_model(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    epochs=50,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a1f25",
   "metadata": {},
   "source": [
    "## Section 4: Plot Training History\n",
    "\n",
    "Visualize loss and accuracy curves to understand model learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35361177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = plot_training_history(history)\n",
    "plt.savefig(str(BASE_DIR / 'outputs' / 'training_history.png'), dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c20653",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate Model\n",
    "\n",
    "Test the model on validation data and report metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "metrics = evaluate_model(model, X_val, y_val, idx_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3055f6",
   "metadata": {},
   "source": [
    "## Section 6: Save Trained Model\n",
    "\n",
    "Persist the model for use in inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = MODELS_DIR / 'lstm_mudra_model.h5'\n",
    "save_model(model, str(model_path))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: Bi-Directional LSTM\")\n",
    "print(f\"  - Input shape: {input_shape}\")\n",
    "print(f\"  - LSTM units: 64 (bidirectional)\")\n",
    "print(f\"  - Dense units: 32\")\n",
    "print(f\"  - Output classes: {num_classes} {list(idx_to_label.values())}\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  - Training samples: {len(X_train)}\")\n",
    "print(f\"  - Validation samples: {len(X_val)}\")\n",
    "print(f\"  - Validation accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"\\nModel saved to: {model_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f681b",
   "metadata": {},
   "source": [
    "## Summary: Phase 5 Complete ✓\n",
    "\n",
    "**What we've accomplished:**\n",
    "1. ✓ Built Bi-Directional LSTM model\n",
    "2. ✓ Trained on properly-windowed temporal sequences\n",
    "3. ✓ Used categorical cross-entropy + Adam optimizer\n",
    "4. ✓ Applied early stopping to prevent overfitting\n",
    "5. ✓ Plotted training loss and accuracy curves\n",
    "6. ✓ Evaluated on validation set\n",
    "7. ✓ Saved trained model\n",
    "\n",
    "**Key improvements over earlier attempt:**\n",
    "- ✓ Proper window-label alignment (fixed misalignment bug)\n",
    "- ✓ Synthetic data generation ensures known ground truth\n",
    "- ✓ Single LSTM layer suitable for review (not over-engineered)\n",
    "- ✓ Clear, interpretable model architecture\n",
    "\n",
    "**Next steps (Phase 6):**\n",
    "- Load trained model\n",
    "- Extract keypoints from test video\n",
    "- Create temporal windows\n",
    "- Make end-to-end predictions\n",
    "- Generate JSON output with mudra sequences\n",
    "- Visualize results with landmarks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
